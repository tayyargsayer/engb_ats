{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:05:19.159173Z",
     "start_time": "2024-06-13T07:05:18.377792Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyC3xJL609lQTJ2grLRSXKLGjJceRMyqHkc\")"
   ],
   "id": "106919392f6b191b",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:12:15.844190Z",
     "start_time": "2024-06-13T07:12:15.840162Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Modelin Ayarları\n",
    "model_1_ayarları = {\n",
    "    \"temperature\": 0.5,\n",
    "    \"top_p\": 0.9,\n",
    "    \"top_k\": 40,\n",
    "}"
   ],
   "id": "f809dcfcea251d5",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:13:27.362212Z",
     "start_time": "2024-06-13T07:13:27.358033Z"
    }
   },
   "cell_type": "code",
   "source": [
    "güvenlik_ayarları = [\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
    "        \"threshold\": \"BLOCK_NONE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
    "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
    "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
    "        \"threshold\": \"BLOCK_MEDIUM_AND_ABOVE\",\n",
    "    },\n",
    "]"
   ],
   "id": "634d101fa16accd3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:13:43.116880Z",
     "start_time": "2024-06-13T07:13:43.109220Z"
    }
   },
   "cell_type": "code",
   "source": "models = genai.list_models()",
   "id": "2f5857c7d9d1b2f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object list_models at 0x000001A91BDDE040>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:14:25.030438Z",
     "start_time": "2024-06-13T07:14:23.848608Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for model in models:\n",
    "    print(model)"
   ],
   "id": "8e72880ded6834e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(name='models/chat-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 Chat (Legacy)',\n",
      "      description='A legacy text-only model optimized for chat conversations',\n",
      "      input_token_limit=4096,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateMessage', 'countMessageTokens'],\n",
      "      temperature=0.25,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/text-bison-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='PaLM 2 (Legacy)',\n",
      "      description='A legacy model that understands text and generates text as an output',\n",
      "      input_token_limit=8196,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateText', 'countTextTokens', 'createTunedTextModel'],\n",
      "      temperature=0.7,\n",
      "      top_p=0.95,\n",
      "      top_k=40)\n",
      "Model(name='models/embedding-gecko-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding Gecko',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=1024,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedText', 'countTextTokens'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro 001 (Tuning)',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is a stable '\n",
      "                   'model that supports tuning.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createTunedModel'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Latest',\n",
      "      description=('The best model for scaling across a wide range of tasks. This is the latest '\n",
      "                   'model.'),\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-1.0-pro-vision-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/gemini-1.5-flash',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash 001',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-flash-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Flash Latest',\n",
      "      description='Fast and versatile multimodal model for scaling across diverse tasks',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro',\n",
      "      description='Mid-size multimodal model that supports up to 1 million tokens',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro 001',\n",
      "      description='Mid-size multimodal model that supports up to 1 million tokens',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens', 'createCachedContent'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-1.5-pro-latest',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.5 Pro Latest',\n",
      "      description='Mid-size multimodal model that supports up to 1 million tokens',\n",
      "      input_token_limit=1048576,\n",
      "      output_token_limit=8192,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=1.0,\n",
      "      top_p=0.95,\n",
      "      top_k=64)\n",
      "Model(name='models/gemini-pro',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro',\n",
      "      description='The best model for scaling across a wide range of tasks',\n",
      "      input_token_limit=30720,\n",
      "      output_token_limit=2048,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.9,\n",
      "      top_p=1.0,\n",
      "      top_k=None)\n",
      "Model(name='models/gemini-pro-vision',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Gemini 1.0 Pro Vision',\n",
      "      description='The best image understanding model to handle a broad range of applications',\n",
      "      input_token_limit=12288,\n",
      "      output_token_limit=4096,\n",
      "      supported_generation_methods=['generateContent', 'countTokens'],\n",
      "      temperature=0.4,\n",
      "      top_p=1.0,\n",
      "      top_k=32)\n",
      "Model(name='models/embedding-001',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Embedding 001',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/text-embedding-004',\n",
      "      base_model_id='',\n",
      "      version='004',\n",
      "      display_name='Text Embedding 004',\n",
      "      description='Obtain a distributed representation of a text.',\n",
      "      input_token_limit=2048,\n",
      "      output_token_limit=1,\n",
      "      supported_generation_methods=['embedContent'],\n",
      "      temperature=None,\n",
      "      top_p=None,\n",
      "      top_k=None)\n",
      "Model(name='models/aqa',\n",
      "      base_model_id='',\n",
      "      version='001',\n",
      "      display_name='Model that performs Attributed Question Answering.',\n",
      "      description=('Model trained to return answers to questions that are grounded in provided '\n",
      "                   'sources, along with estimating answerable probability.'),\n",
      "      input_token_limit=7168,\n",
      "      output_token_limit=1024,\n",
      "      supported_generation_methods=['generateAnswer'],\n",
      "      temperature=0.2,\n",
      "      top_p=1.0,\n",
      "      top_k=40)\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:16:56.914694Z",
     "start_time": "2024-06-13T07:16:56.910329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = genai.GenerativeModel(\n",
    "    model_name = \"gemini-1.5-flash-latest\",\n",
    "    safety_settings = güvenlik_ayarları,\n",
    "    generation_config = model_1_ayarları,\n",
    ")"
   ],
   "id": "4d6119e9665e2895",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:20:31.746518Z",
     "start_time": "2024-06-13T07:20:31.742575Z"
    }
   },
   "cell_type": "code",
   "source": "prompt = \"Yugioh, babaannesi kaçırılan bir gencin hikayesidir\"",
   "id": "16cf0212cba23ea3",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-13T07:20:39.121493Z",
     "start_time": "2024-06-13T07:20:31.922518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = model.generate_content(prompt).text\n",
    "response"
   ],
   "id": "d96fd907eb35068f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yugi Mutou, hayatı boyunca kart oyunlarına tutkuyla bağlı bir gençti. En sevdiği oyun ise, babasının ona miras bıraktığı antik bir Mısır oyunuydu: Duel Monsters. Bu oyunda, kartlar canlanan yaratıklar haline dönüşüyor ve oyuncular, stratejik düşünme ve kartlarını ustaca kullanarak birbirleriyle savaşıyorlardı.\\n\\nBir gün, Yugi\\'nin hayatı altüst oldu. Babası, Kaiba Corporation\\'ın başkanı Seto Kaiba tarafından kaçırıldı. Kaiba, babasının elinde bulunan \"Millennium Puzzle\"ı istiyordu. Bu gizemli bulmaca, Yugi\\'nin babasının yıllarca araştırdığı ve antik Mısır\\'ın en güçlü artefaklarından biri olduğu söyleniyordu.\\n\\nYugi, babasını kurtarmak için Kaiba\\'ya meydan okumaya karar verdi. Ancak Kaiba, sadece Duel Monsters\\'ta değil, aynı zamanda acımasızlığı ve gücüyle de biliniyordu. Yugi\\'nin karşısına, Kaiba\\'nın geliştirdiği güçlü bir savaş robotu çıktı. Bu robot, Yugi\\'nin tüm kartlarını yok etmek için programlanmıştı.\\n\\nYugi, umutsuzluğa kapılmak üzereyken, Millennium Puzzle\\'ın gücünü keşfetti. Bulmacayı çözerek, içinde gizlenen ruhu uyandırdı ve bu ruh, Yugi\\'ye Duel Monsters\\'ta benzeri görülmemiş bir güç verdi. Yugi, Kaiba\\'nın robotuna karşı savaştı ve sonunda onu yendi.\\n\\nKaiba, yenilgisine rağmen babasını serbest bırakmayı reddetti. Ancak Yugi, Kaiba\\'nın kalbinin derinliklerindeki kırgınlığı ve yalnızlığı gördü. Yugi, Kaiba\\'ya arkadaşlık teklif etti ve ona Duel Monsters\\'ın sadece bir oyun değil, aynı zamanda insanların birbirlerine bağlanabileceği bir yol olduğunu gösterdi.\\n\\nKaiba, Yugi\\'nin teklifine şaşırdı. Yugi\\'nin samimiyeti ve gücü, Kaiba\\'nın kalbini yumuşattı ve sonunda babasını serbest bıraktı. Yugi, babasını kurtarmış ve aynı zamanda yeni bir arkadaş kazanmıştı.\\n\\nYugi, Duel Monsters\\'ta ustalaşmaya devam etti ve birçok güçlü duelistle karşılaştı. Bu yolculukta, yeni arkadaşlar edindi, düşmanlarını yendi ve kendi gücünü keşfetti. Yugi, Duel Monsters\\'ın sadece bir oyun olmadığını, insanların birbirlerine bağlanabileceği, hayallerini gerçekleştirebileceği ve hayattaki zorlukların üstesinden gelebileceği bir yol olduğunu kanıtladı.\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f99bf9187eb78c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
